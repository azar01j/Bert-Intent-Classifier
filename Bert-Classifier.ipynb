{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b155c01-68a4-43e2-9d20-c1d5b0856899",
   "metadata": {},
   "source": [
    "**This Notebook contains Steps to Refernce a Bert Model and custom train it with our own Questions Dataset**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c459a1c-7e8d-48bc-93a2-32eb46e4afdc",
   "metadata": {},
   "source": [
    "## Step 1 : Importing the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a99614-5882-4624-80ea-7301348ed54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import evaluate\n",
    "from transformers import DataCollatorWithPadding\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176f349-034c-45da-8cda-d774d2f6edff",
   "metadata": {},
   "source": [
    "## Step 2 : Referencing the Bert Model and Declaring the Categories of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6e6cc4f-6af7-47df-a5b3-eea24510ddce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at google-bert/bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "model_path  =  \"google-bert/bert-base-uncased\"\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "id2label = {0:\"Insights\",1:\"Data\"}\n",
    "label2id = {1:\"Data\",0:\"Insights\"}\n",
    "\n",
    "model =  AutoModelForSequenceClassification.from_pretrained(model_path,num_labels=2,id2label=id2label,label2id=label2id,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d704e4-b69c-4de5-99fc-062df77b99cd",
   "metadata": {},
   "source": [
    "## Step 3: Getting the Dataset Ready to train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ce005e9-158b-46b3-8813-bff7c20d9c52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                  text  labels\n",
      "121  How do weather patterns influence fishing indu...       0\n",
      "122     How does humidity affect precipitation levels?       0\n",
      "123    What is the average humidity level in February?       1\n",
      "124  Can we identify patterns in extreme weather ev...       0\n",
      "125  What is the impact of weather on public transp...       0\n",
      "126  List tht actual wind speed on the day 26th Feb...       1\n",
      "127               What was the total snowfall in July?       1\n",
      "128  How do weather patterns influence tourism trends?       0\n",
      "129  How do weather patterns affect wildlife migrat...       0\n",
      "130        What is the average temperature in October?       1\n",
      "131       What is the average temperature in November?       1\n",
      "132     What is the average wind direction in October?       1\n",
      "133         What is the average temperature in August?       1\n",
      "134  What is the highest recorded air pressure in t...       1\n",
      "135  What was the maximum rainfall recorded in Sept...       1\n",
      "136              What was the total snowfall in April?       1\n",
      "137  How do weather patterns affect outdoor adverti...       0\n",
      "138  What is the impact of weather on road conditions?       0\n",
      "139    What is the average humidity level in December?       1\n",
      "140  What are the long-term effects of climate chan...       0\n",
      "141  What was the minimum temperature recorded in D...       1\n",
      "142                What is the total snowfall in June?       1\n"
     ]
    }
   ],
   "source": [
    "df= pd.read_csv(f\"./weather-questions.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_insight = df[df['label']==0]\n",
    "df_data = df[df['label']==1]\n",
    "\n",
    "\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df_insight_sample = df_insight.sample(len(df_insight), random_state=42)\n",
    "df_data_sample = df_data.sample(len(df_data), random_state=42)\n",
    "\n",
    "\n",
    "#print(df_data)\n",
    "\n",
    "\n",
    "df_insight_sample = df_insight_sample.assign(isdata=False)\n",
    "df_insight_sample = df_insight_sample.drop('label',axis=1)\n",
    "df_data_sample = df_data_sample.assign(isdata=True)\n",
    "df_data_sample = df_data_sample.drop('label',axis=1)\n",
    "\n",
    "# Concatenate the samples to create a new balanced dataset\n",
    "balanced_df = pd.concat([df_insight_sample, df_data_sample])\n",
    "balanced_df.columns = ['text', 'labels']\n",
    "\n",
    "# convert labels column to int\n",
    "balanced_df['labels'] = balanced_df['labels'].astype(int)\n",
    "\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_ds = Dataset.from_pandas(balanced_df)\n",
    "\n",
    "\n",
    "# Split into train, validation, and test sets (e.g., 70% train, 15% validation, 15% test)\n",
    "train_frac = 0.7\n",
    "valid_frac = 0.15\n",
    "test_frac = 0.15\n",
    "\n",
    "# define train and validation size\n",
    "train_size = int(train_frac * len(df))\n",
    "valid_size = int(valid_frac * len(df))\n",
    "\n",
    "# create train, validation, and test datasets\n",
    "train_df = balanced_df[:train_size]\n",
    "valid_df = balanced_df[train_size:train_size + valid_size]\n",
    "test_df = balanced_df[train_size + valid_size:]\n",
    "\n",
    "# Convert the pandas DataFrames back to Hugging Face Datasets\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': valid_ds,\n",
    "    'test': test_ds\n",
    "})\n",
    "\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f85e0d-16f9-40bc-8b60-723660b925c8",
   "metadata": {},
   "source": [
    "## Step 4: Disbale the unnesecarry parameters to Make the model much lighter / Mapping and Tokeninzing the Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d100a4f2-61ad-4348-be0b-7915731d6558",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb28fa0f954842cabbf0e7c0431c548e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/100 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "feaffed08697465588c9dbd56307f058",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/21 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9898820cd2b443b5bce2b985b191eda8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/22 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for name, param in model.base_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"pooler\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_data = dataset_dict.map(preprocess_function,batched=True)\n",
    "\n",
    "data_collator =  DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9c731-af57-4334-8d78-59636709debf",
   "metadata": {},
   "source": [
    "## Step4 : Defining the Compute Metrics and Setting up accruacy levels to analyse the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5514229e-b6a4-49c2-99a7-c156e438f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # get predictions\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # apply softmax to get probabilities\n",
    "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, keepdims=True)\n",
    "    # use probabilities of the positive class for ROC AUC\n",
    "    positive_class_probs = probabilities[:, 1]\n",
    "    # compute auc\n",
    "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, references=labels)['roc_auc'],3)\n",
    "    \n",
    "    # predict most probable class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    # compute accuracy\n",
    "    acc = np.round(accuracy.compute(predictions=predicted_classes, references=labels)['accuracy'],3)\n",
    "    \n",
    "    return {\"Accuracy\": acc, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fadcee-561d-4d51-a966-a978271b35e7",
   "metadata": {},
   "source": [
    "## Step5 : Declaring the traning parameters and saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb4c451-9a47-48b5-a898-9d08d46bc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "training_args =  TrainingArguments(\n",
    "    output_dir = \"bert-intent-classifier_cbase\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9765dbde-de1e-497d-b303-bfb2ad1ac5fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\azar-test\\AppData\\Local\\Temp\\2\\ipykernel_6596\\2732273287.py:1: FutureWarning: `tokenizer` is deprecated and will be removed in version 5.0.0 for `Trainer.__init__`. Use `processing_class` instead.\n",
      "  trainer = Trainer(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='130' max='130' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [130/130 00:40, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.649800</td>\n",
       "      <td>0.389397</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.404900</td>\n",
       "      <td>0.310827</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.277800</td>\n",
       "      <td>0.142245</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.182500</td>\n",
       "      <td>0.097272</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.138400</td>\n",
       "      <td>0.050333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.091600</td>\n",
       "      <td>0.038005</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.072100</td>\n",
       "      <td>0.027868</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.049200</td>\n",
       "      <td>0.026023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.057500</td>\n",
       "      <td>0.025553</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.048400</td>\n",
       "      <td>0.024219</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=130, training_loss=0.19722308012155387, metrics={'train_runtime': 58.4058, 'train_samples_per_second': 17.122, 'train_steps_per_second': 2.226, 'total_flos': 7066998502560.0, 'train_loss': 0.19722308012155387, 'epoch': 10.0})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780ca76-36e7-4601-8a6b-995965155e5e",
   "metadata": {},
   "source": [
    "## Step 7 : Testing the trained model with questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "07c49c5e-2628-456d-9089-dbba4a42fff0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1e30c4219c14ec88fefd4b0f046e00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Can you analyze why user engagement dropped after 14th of Feb 2025 ?\n",
      "Predicted Label: Insights\n",
      "\n",
      "Text: What are all the factors which were influencing the temprature on the city with postal code 02047 ?\n",
      "Predicted Label: Insights\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Sample text inputs for testing\n",
    "test_texts = [\"Can you analyze why user engagement dropped after 14th of Feb 2025 ?\", \"What are all the factors which were influencing the temprature on the city with postal code 02047 ?\"]\n",
    "\n",
    "# Create a Pandas DataFrame (matching the format of your dataset)\n",
    "test_df = pd.DataFrame({\"text\": test_texts})\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "predictions = trainer.predict(tokenized_test_dataset)\n",
    "logits = predictions.predictions \n",
    "\n",
    "# Get class predictions\n",
    "predicted_classes = np.argmax(logits, axis=1)\n",
    "\n",
    "# Map class IDs back to labels (ensure this matches your training labels)\n",
    "id2label = {0: \"Insights\", 1: \"Data\"}  \n",
    "predicted_labels = [id2label[label] for label in predicted_classes]\n",
    "\n",
    "# Print results\n",
    "for text, label in zip(test_texts, predicted_labels):\n",
    "    print(f\"Text: {text}\\nPredicted Label: {label}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e315760-f75e-4510-962f-5317dd4e7317",
   "metadata": {},
   "source": [
    "### Step 8: After testing the model , now we can push this to Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "150cec29-5be5-4b45-bd47-c13a8038f470",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d91447236c2046e1b89561229cee36fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/438M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/Azar-J/question-classifier/commit/a9e840926e6ce1e5dbb17b0f246836ae6ddae5ed', commit_message='Upload BertForSequenceClassification', commit_description='', oid='a9e840926e6ce1e5dbb17b0f246836ae6ddae5ed', pr_url=None, repo_url=RepoUrl('https://huggingface.co/Azar-J/question-classifier', endpoint='https://huggingface.co', repo_type='model', repo_id='Azar-J/question-classifier'), pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.push_to_hub('Azar-J/question-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bed059-d10d-4d09-a59f-b5547385f2e4",
   "metadata": {},
   "source": [
    "### Now the Model has been pushed and now will be available for use and hosting them in Snowflake Model Registry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
