{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8b155c01-68a4-43e2-9d20-c1d5b0856899",
   "metadata": {},
   "source": [
    "**This Notebook contains Steps to Refernce a Bert Model and custom train it with our own Questions Dataset**\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c459a1c-7e8d-48bc-93a2-32eb46e4afdc",
   "metadata": {},
   "source": [
    "## Step 1 : Importing the necessary libraries\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72a99614-5882-4624-80ea-7301348ed54a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\n",
    "from transformers import TrainingArguments, Trainer, AutoTokenizer, AutoModelForSequenceClassification\n",
    "import evaluate\n",
    "from transformers import DataCollatorWithPadding\n",
    "import transformers\n",
    "import pandas as pd\n",
    "from datasets import DatasetDict, Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c176f349-034c-45da-8cda-d774d2f6edff",
   "metadata": {},
   "source": [
    "## Step 2 : Referencing the Bert Model and Declaring the Categories of classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6e6cc4f-6af7-47df-a5b3-eea24510ddce",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model_path  =  \"google-bert/bert-base-uncased\"\n",
    "\n",
    "tokenizer =  AutoTokenizer.from_pretrained(model_path)\n",
    "\n",
    "id2label = {0:\"Insights\",1:\"Data\"}\n",
    "label2id = {1:\"Data\",0:\"Insights\"}\n",
    "\n",
    "model =  AutoModelForSequenceClassification.from_pretrained(model_path,num_labels=2,id2label=id2label,label2id=label2id,)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86d704e4-b69c-4de5-99fc-062df77b99cd",
   "metadata": {},
   "source": [
    "## Step 3: Getting the Dataset Ready to train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ce005e9-158b-46b3-8813-bff7c20d9c52",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(f\"./weather-questions.csv\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df_insight = df[df['label']==0]\n",
    "df_data = df[df['label']==1]\n",
    "\n",
    "\n",
    "df['label'] = df['label'].astype(int)\n",
    "\n",
    "\n",
    "\n",
    "df_insight_sample = df_insight.sample(len(df_insight), random_state=42)\n",
    "df_data_sample = df_data.sample(len(df_data), random_state=42)\n",
    "\n",
    "\n",
    "#print(df_data)\n",
    "\n",
    "\n",
    "df_insight_sample = df_insight_sample.assign(isdata=False)\n",
    "df_insight_sample = df_insight_sample.drop('label',axis=1)\n",
    "df_data_sample = df_data_sample.assign(isdata=True)\n",
    "df_data_sample = df_data_sample.drop('label',axis=1)\n",
    "\n",
    "# Concatenate the samples to create a new balanced dataset\n",
    "balanced_df = pd.concat([df_insight_sample, df_data_sample])\n",
    "balanced_df.columns = ['text', 'labels']\n",
    "\n",
    "# convert labels column to int\n",
    "balanced_df['labels'] = balanced_df['labels'].astype(int)\n",
    "\n",
    "balanced_df = balanced_df.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "balanced_ds = Dataset.from_pandas(balanced_df)\n",
    "\n",
    "\n",
    "# Split into train, validation, and test sets (e.g., 70% train, 15% validation, 15% test)\n",
    "train_frac = 0.7\n",
    "valid_frac = 0.15\n",
    "test_frac = 0.15\n",
    "\n",
    "# define train and validation size\n",
    "train_size = int(train_frac * len(df))\n",
    "valid_size = int(valid_frac * len(df))\n",
    "\n",
    "# create train, validation, and test datasets\n",
    "train_df = balanced_df[:train_size]\n",
    "valid_df = balanced_df[train_size:train_size + valid_size]\n",
    "test_df = balanced_df[train_size + valid_size:]\n",
    "\n",
    "# Convert the pandas DataFrames back to Hugging Face Datasets\n",
    "train_ds = Dataset.from_pandas(train_df)\n",
    "valid_ds = Dataset.from_pandas(valid_df)\n",
    "test_ds = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "# Combine into a DatasetDict\n",
    "dataset_dict = DatasetDict({\n",
    "    'train': train_ds,\n",
    "    'validation': valid_ds,\n",
    "    'test': test_ds\n",
    "})\n",
    "\n",
    "print(test_df)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f85e0d-16f9-40bc-8b60-723660b925c8",
   "metadata": {},
   "source": [
    "## Step 4: Disbale the unnesecarry parameters to Make the model much lighter / Mapping and Tokeninzing the Training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d100a4f2-61ad-4348-be0b-7915731d6558",
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, param in model.base_model.named_parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "for name, param in model.base_model.named_parameters():\n",
    "    if \"pooler\" in name:\n",
    "        param.requires_grad = True\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True)\n",
    "\n",
    "\n",
    "tokenized_data = dataset_dict.map(preprocess_function,batched=True)\n",
    "\n",
    "data_collator =  DataCollatorWithPadding(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc9c731-af57-4334-8d78-59636709debf",
   "metadata": {},
   "source": [
    "## Step4 : Defining the Compute Metrics and Setting up accruacy levels to analyse the output of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5514229e-b6a4-49c2-99a7-c156e438f83f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load metrics\n",
    "accuracy = evaluate.load(\"accuracy\")\n",
    "auc_score = evaluate.load(\"roc_auc\")\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    # get predictions\n",
    "    predictions, labels = eval_pred\n",
    "    \n",
    "    # apply softmax to get probabilities\n",
    "    probabilities = np.exp(predictions) / np.exp(predictions).sum(-1, keepdims=True)\n",
    "    # use probabilities of the positive class for ROC AUC\n",
    "    positive_class_probs = probabilities[:, 1]\n",
    "    # compute auc\n",
    "    auc = np.round(auc_score.compute(prediction_scores=positive_class_probs, references=labels)['roc_auc'],3)\n",
    "    \n",
    "    # predict most probable class\n",
    "    predicted_classes = np.argmax(predictions, axis=1)\n",
    "    # compute accuracy\n",
    "    acc = np.round(accuracy.compute(predictions=predicted_classes, references=labels)['accuracy'],3)\n",
    "    \n",
    "    return {\"Accuracy\": acc, \"AUC\": auc}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87fadcee-561d-4d51-a966-a978271b35e7",
   "metadata": {},
   "source": [
    "## Step5 : Declaring the traning parameters and saving the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fbb4c451-9a47-48b5-a898-9d08d46bc479",
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = 2e-4\n",
    "batch_size = 8\n",
    "num_epochs = 10\n",
    "\n",
    "\n",
    "training_args =  TrainingArguments(\n",
    "    output_dir = \"bert-intent-classifier_cbase\",\n",
    "    learning_rate=lr,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size,\n",
    "    num_train_epochs=num_epochs,\n",
    "    logging_strategy=\"epoch\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    load_best_model_at_end=True,\n",
    ")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9765dbde-de1e-497d-b303-bfb2ad1ac5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=tokenized_data[\"train\"],\n",
    "    eval_dataset=tokenized_data[\"test\"],\n",
    "    tokenizer=tokenizer,\n",
    "    data_collator=data_collator,\n",
    "    compute_metrics=compute_metrics,\n",
    ")\n",
    "\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c780ca76-36e7-4601-8a6b-995965155e5e",
   "metadata": {},
   "source": [
    "## Step 7 : Testing the trained model with questions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07c49c5e-2628-456d-9089-dbba4a42fff0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "import numpy as np\n",
    "\n",
    "# Sample text inputs for testing\n",
    "test_texts = [\"Can you analyze why user engagement dropped after 14th of Feb 2025 ?\", \"What are all the factors which were influencing the temprature on the city with postal code 02047 ?\"]\n",
    "\n",
    "# Create a Pandas DataFrame (matching the format of your dataset)\n",
    "test_df = pd.DataFrame({\"text\": test_texts})\n",
    "\n",
    "# Convert to Hugging Face Dataset\n",
    "test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "\n",
    "def preprocess_function(examples):\n",
    "    return tokenizer(examples[\"text\"], truncation=True, padding=\"max_length\", max_length=512)\n",
    "\n",
    "tokenized_test_dataset = test_dataset.map(preprocess_function, batched=True)\n",
    "\n",
    "predictions = trainer.predict(tokenized_test_dataset)\n",
    "logits = predictions.predictions \n",
    "\n",
    "# Get class predictions\n",
    "predicted_classes = np.argmax(logits, axis=1)\n",
    "\n",
    "# Map class IDs back to labels (ensure this matches your training labels)\n",
    "id2label = {0: \"Insights\", 1: \"Data\"}  \n",
    "predicted_labels = [id2label[label] for label in predicted_classes]\n",
    "\n",
    "# Print results\n",
    "for text, label in zip(test_texts, predicted_labels):\n",
    "    print(f\"Text: {text}\\nPredicted Label: {label}\\n\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e315760-f75e-4510-962f-5317dd4e7317",
   "metadata": {},
   "source": [
    "### Step 8: After testing the model , now we can push this to Hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150cec29-5be5-4b45-bd47-c13a8038f470",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.push_to_hub('Azar-J/question-classifier')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8bed059-d10d-4d09-a59f-b5547385f2e4",
   "metadata": {},
   "source": [
    "### Now the Model has been pushed and now will be available for use and hosting them in Snowflake Model Registry"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
